{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthik1946/01_c/blob/main/dl_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx0wO6fQMjKU",
        "outputId": "65a83a48-eaba-4304-9061-0f155535007a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCUmgTLYO7W9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3607b26-9a75-4ff5-e04a-5319ca441500"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(194369, 38)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Set display options to show more columns and rows\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "file_names = [\"/content/drive/MyDrive/S-1/Train/1.txt\", \"/content/drive/MyDrive/S-1/Train/2.txt\", \"/content/drive/MyDrive/S-1/Train/3.txt\", \"/content/drive/MyDrive/S-1/Train/4.txt\", \"/content/drive/MyDrive/S-1/Train/5.txt\", \"/content/drive/MyDrive/S-1/Train/6.txt\", \"/content/drive/MyDrive/S-1/Train/7.txt\", \"/content/drive/MyDrive/S-1/Train/8.txt\"]\n",
        "\n",
        "concatenated_data = pd.DataFrame()\n",
        "\n",
        "for file_name in file_names:\n",
        "    data = pd.read_csv(file_name, delimiter=',', header=None)\n",
        "    concatenated_data = pd.concat([concatenated_data, data], axis=0)\n",
        "\n",
        "concatenated_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "concatenated_data.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoHCbiwXpLKB",
        "outputId": "cc7880d9-c12d-42ce-e88f-8b8bafe875fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.3.25)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.3)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.11.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBUHMTresE2H"
      },
      "outputs": [],
      "source": [
        "import tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_BlK0xEoqxl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apK04DI5IxO9",
        "outputId": "a5decbdb-7431-4e64-dd4f-ab24427129d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of predictions: (170675, 1)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Set display options to show more columns and rows\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "file_names = [\"/content/drive/MyDrive/S-1/Test_Label/1.txt\",\n",
        "              \"/content/drive/MyDrive/S-1/Test_Label/2.txt\",\n",
        "              \"/content/drive/MyDrive/S-1/Test_Label/3.txt\",\n",
        "              \"/content/drive/MyDrive/S-1/Test_Label/4.txt\",\n",
        "              \"/content/drive/MyDrive/S-1/Test_Label/5.txt\",\n",
        "              \"/content/drive/MyDrive/S-1/Test_Label/6.txt\",\n",
        "              \"/content/drive/MyDrive/S-1/Test_Label/7.txt\"]\n",
        "\n",
        "X_test = pd.DataFrame()\n",
        "\n",
        "for file_name in file_names:\n",
        "    data = pd.read_csv(file_name, delimiter=',', header=None)\n",
        "    X_test = pd.concat([X_test, data], axis=0)\n",
        "\n",
        "X_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(\"Shape of predictions:\", X_test.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Set display options to show more columns and rows\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "file_names = [\"/content/drive/MyDrive/S-1/Test/1.txt\", \"/content/drive/MyDrive/S-1/Test/2.txt\", \"/content/drive/MyDrive/S-1/Test/3.txt\", \"/content/drive/MyDrive/S-1/Test/4.txt\", \"/content/drive/MyDrive/S-1/Test/5.txt\", \"/content/drive/MyDrive/S-1/Test/6.txt\", \"/content/drive/MyDrive/S-1/Test/7.txt\"]\n",
        "\n",
        "X_data = pd.DataFrame()\n",
        "\n",
        "for file_name in file_names:\n",
        "    data = pd.read_csv(file_name, delimiter=',', header=None)\n",
        "    X_data = pd.concat([X_data, data], axis=0)\n",
        "\n",
        "X_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "X_data.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPCQu8pbox5O",
        "outputId": "6b3cfa19-4795-4519-ea1d-b9934d1b321d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(170675, 38)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Assuming concatenated_data is your DataFrame with 38 sensor columns\n",
        "multivariate_data = concatenated_data.copy()\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(multivariate_data)\n",
        "\n",
        "# Define sequences for training\n",
        "def create_sequences(data, sequence_length):\n",
        "    sequences = []\n",
        "    for i in range(len(data) - sequence_length + 1):\n",
        "        seq = data[i:i + sequence_length, :]\n",
        "        sequences.append(seq)\n",
        "    return np.array(sequences)\n",
        "\n",
        "sequence_length = 10  # Adjust based on your requirements\n",
        "X = create_sequences(scaled_data, sequence_length)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val = train_test_split(X, test_size=0.2, shuffle=False)\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=X_train.shape[2]))  # Output layer with the same number of features as sensors\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Define a ModelCheckpoint callback to save the best weights\n",
        "checkpoint = ModelCheckpoint(\"best_model_weights.h5\", save_best_only=True, save_weights_only=True, monitor='val_loss', mode='min', verbose=1)\n",
        "\n",
        "# Train the model\n",
        "epochs = 3  # Adjust the number of epochs based on your requirements\n",
        "best_val_accuracy = 0.0\n",
        "best_threshold = 0.4551  # Initial threshold\n",
        "for epoch in range(epochs):\n",
        "    history = model.fit(X_train, X_train[:, -1, :], epochs=1, batch_size=32, validation_data=(X_val, X_val[:, -1, :]), callbacks=[checkpoint], verbose=1)\n",
        "\n",
        "    # Calculate validation accuracy after each epoch\n",
        "    predictions_val = model.predict(X_val)\n",
        "    mse_val = np.mean(np.square(X_val[:, -1, :] - predictions_val), axis=1)\n",
        "\n",
        "    # Calculate dynamic threshold based on the validation MSE\n",
        "    threshold_val = np.percentile(mse_val, 95)  # Example: Use the 95th percentile of validation MSE as the threshold\n",
        "\n",
        "    anomalies_val = (mse_val > threshold_val).astype(int)\n",
        "    zeros_list = np.zeros_like(anomalies_val)\n",
        "    validation_accuracy = np.sum(anomalies_val == zeros_list) / zeros_list.shape[0]\n",
        "\n",
        "    # Adjust threshold dynamically based on validation accuracy\n",
        "    if validation_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = validation_accuracy\n",
        "        best_threshold = threshold_val\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} - Validation Accuracy: {validation_accuracy * 100:.2f}% - Threshold: {best_threshold:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOUOc4tK9xE7",
        "outputId": "cacb41d9-0629-4fc7-f01b-fda13c142c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4858/4859 [============================>.] - ETA: 0s - loss: 0.1546\n",
            "Epoch 1: val_loss improved from inf to 0.25830, saving model to best_model_weights.h5\n",
            "4859/4859 [==============================] - 44s 9ms/step - loss: 0.1546 - val_loss: 0.2583\n",
            "1215/1215 [==============================] - 5s 4ms/step\n",
            "Epoch 1/3 - Validation Accuracy: 95.00% - Threshold: 0.5875\n",
            "4858/4859 [============================>.] - ETA: 0s - loss: 0.1111\n",
            "Epoch 1: val_loss improved from 0.25830 to 0.22208, saving model to best_model_weights.h5\n",
            "4859/4859 [==============================] - 42s 9ms/step - loss: 0.1111 - val_loss: 0.2221\n",
            "1215/1215 [==============================] - 5s 4ms/step\n",
            "Epoch 2/3 - Validation Accuracy: 95.00% - Threshold: 0.5875\n",
            "4856/4859 [============================>.] - ETA: 0s - loss: 0.1044\n",
            "Epoch 1: val_loss improved from 0.22208 to 0.20430, saving model to best_model_weights.h5\n",
            "4859/4859 [==============================] - 42s 9ms/step - loss: 0.1043 - val_loss: 0.2043\n",
            "1215/1215 [==============================] - 4s 3ms/step\n",
            "Epoch 3/3 - Validation Accuracy: 95.00% - Threshold: 0.5875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a DataFrame named X_test with 38 sensor columns\n",
        "X_test_np = X_test.to_numpy()\n",
        "\n",
        "# Create sequences for testing\n",
        "X_test_sequences = create_sequences(X_test_np, sequence_length)\n",
        "\n",
        "# Reshape X_test_sequences to match the input shape of the model\n",
        "X_test_sequences = X_test_sequences.reshape(-1, sequence_length, X_test_np.shape[1])\n",
        "\n",
        "# Use the trained model to predict sequences on the test data\n",
        "predictions_test = model.predict(X_test_sequences)\n",
        "\n",
        "# Reshape predictions to match the shape of X_test\n",
        "predictions_test = predictions_test[:, 0, :].reshape(-1, X_test_np.shape[1])\n",
        "\n",
        "# Now, you can use predictions_test for further analysis or evaluation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "id": "1r-aJKAlXMdU",
        "outputId": "1dabf6ea-997a-4722-9329-b39e8afdd782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-4b8be42db02b>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Use the trained model to predict sequences on the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpredictions_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Reshape predictions to match the shape of X_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_17' (type Sequential).\n    \n    Input 0 of layer \"lstm_17\" is incompatible with the layer: expected shape=(None, None, 38), found shape=(None, 10, 1)\n    \n    Call arguments received by layer 'sequential_17' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 10, 1), dtype=int64)\n      • training=False\n      • mask=None\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1RbKZP-kYUbWbJ538KUViSfpoiojFa26z",
      "authorship_tag": "ABX9TyOxb6amkkFWdh+win5RlSjD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}